{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "584c0c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "root_path = \"/home/minghuan/ppt_learning/logs/images/2025-05-06_16-43-38\"\n",
    "rgb_only_table_path = \"/home/minghuan/ppt_learning/logs/images/2025-05-06_16-43-38/color_1/1746521024751.png\"\n",
    "depth_only_table_path = \"/home/minghuan/ppt_learning/logs/images/2025-05-06_16-43-38/depth_1/1746521024751.npy\"\n",
    "output_path = Path(\"/home/minghuan/ppt_learning/logs/images/2025-05-06_16-43-38/output_pcds\")\n",
    "table_to_robot_base_npy = \"/home/minghuan/ppt_learning/logs/table_to_robot.npy\"\n",
    "image_with_aruco_marker = \"/home/minghuan/ppt_learning/logs/images/2025-05-06_16-43-38/color_1/1746521024751.png\"\n",
    "image_with_aruco_marker = \"/home/minghuan/ppt_learning/tests/cab.png\"\n",
    "gt_obj_file_path = \"/home/minghuan/ppt_learning/logs/gt/T_block_left/T_block_left.obj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a9115a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n",
    "\n",
    "def depth_to_pointcloud(rgb_image, depth_map, intrinsics, depth_max_threshold=1.3):\n",
    "    \"\"\"\n",
    "    将RGB图像和深度图转换为彩色点云\n",
    "    \n",
    "    参数:\n",
    "        rgb_image: RGB图像，numpy数组 (H, W, 3)\n",
    "        depth_map: 深度图，numpy数组 (H, W)\n",
    "        intrinsics: 相机内参矩阵 (3, 3)\n",
    "    \n",
    "    返回:\n",
    "        point_cloud: Open3D点云对象\n",
    "    \"\"\"\n",
    "    # 获取图像尺寸\n",
    "    height, width = depth_map.shape\n",
    "    \n",
    "    # 创建像素坐标网格\n",
    "    v, u = np.mgrid[0:height, 0:width]\n",
    "    \n",
    "    # 重塑为列向量\n",
    "    u = u.reshape(-1)\n",
    "    v = v.reshape(-1)\n",
    "    depth = depth_map.reshape(-1)\n",
    "    \n",
    "    # 过滤无效的深度值（0或负值）\n",
    "    valid_indices = np.logical_and(depth > 0,  depth < depth_max_threshold)\n",
    "    u = u[valid_indices]\n",
    "    v = v[valid_indices]\n",
    "    depth = depth[valid_indices]\n",
    "    \n",
    "    # 获取相机内参\n",
    "    fx = intrinsics[0, 0]  # 焦距x\n",
    "    fy = intrinsics[1, 1]  # 焦距y\n",
    "    cx = intrinsics[0, 2]  # 光心x\n",
    "    cy = intrinsics[1, 2]  # 光心y\n",
    "    \n",
    "    # 计算3D坐标\n",
    "    x = (u - cx) * depth / fx\n",
    "    y = (v - cy) * depth / fy\n",
    "    z = depth\n",
    "    \n",
    "    # 创建点云\n",
    "    points = np.vstack((x, y, z)).T\n",
    "    \n",
    "    # 从RGB图像获取颜色\n",
    "    colors = rgb_image.reshape(-1, 3)[valid_indices] / 255.0\n",
    "    \n",
    "    # 创建Open3D点云对象\n",
    "    point_cloud = o3d.geometry.PointCloud()\n",
    "    point_cloud.points = o3d.utility.Vector3dVector(points)\n",
    "    point_cloud.colors = o3d.utility.Vector3dVector(colors)\n",
    "    \n",
    "    return point_cloud, points\n",
    "\n",
    "def get_intr_matrix(only_table_intrinsics):\n",
    "    \"\"\"\n",
    "    获取相机内参矩阵\n",
    "    \"\"\"\n",
    "    fx = only_table_intrinsics[\"arr_0\"][0][\"fx\"]\n",
    "    fy = only_table_intrinsics[\"arr_0\"][0][\"fy\"]\n",
    "    cx = only_table_intrinsics[\"arr_0\"][0][\"ppx\"]\n",
    "    cy = only_table_intrinsics[\"arr_0\"][0][\"ppy\"]\n",
    "    intrinsics = np.array([[fx, 0, cx],\n",
    "                           [0, fy, cy],\n",
    "                           [0, 0, 1]])\n",
    "    return intrinsics   \n",
    "\n",
    "def estimate_pose(image, charuco_dict, intrinsics_matrix, dist_coeffs, board):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    corners, ids, _ = cv2.aruco.detectMarkers(gray, charuco_dict)\n",
    "    \n",
    "    if len(corners) > 0:\n",
    "        ret, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(corners, ids, gray, board) # can not pass\n",
    "        if charuco_ids is not None and len(charuco_corners) > 3:\n",
    "            valid, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(charuco_corners, charuco_ids, board, intrinsics_matrix, dist_coeffs, None, None)\n",
    "            if valid:\n",
    "                R_target2cam = cv2.Rodrigues(rvec)[0]\n",
    "                t_target2cam = tvec.reshape(3, 1)\n",
    "                target2cam = np.eye(4)\n",
    "                target2cam[:3, :3] = R_target2cam\n",
    "                target2cam[:3, 3] = t_target2cam.reshape(-1)\n",
    "                return np.linalg.inv(target2cam)\n",
    "    return None\n",
    "\n",
    "def load_obj_as_pointcloud(obj_file_path, sample_points=0):\n",
    "    \"\"\"\n",
    "    从OBJ文件中加载3D模型并转换为点云\n",
    "    \n",
    "    参数:\n",
    "        obj_file_path: OBJ文件路径\n",
    "        sample_points: 采样点数量，若为0则使用所有顶点，若大于0则对网格进行采样\n",
    "        \n",
    "    返回:\n",
    "        point_cloud: Open3D点云对象\n",
    "    \"\"\"\n",
    "    print(f\"正在加载OBJ文件: {obj_file_path}\")\n",
    "    \n",
    "    # 加载OBJ文件为网格\n",
    "    mesh = o3d.io.read_triangle_mesh(obj_file_path)\n",
    "    \n",
    "    # 确保网格有法线，如果没有则计算法线\n",
    "    if not mesh.has_vertex_normals():\n",
    "        mesh.compute_vertex_normals()\n",
    "    \n",
    "    print(f\"网格加载完成: {len(mesh.vertices)}个顶点, {len(mesh.triangles)}个三角形\")\n",
    "    \n",
    "    # 从网格中获取点云\n",
    "    if sample_points > 0:\n",
    "        print(f\"对网格进行采样: {sample_points}个点\")\n",
    "        point_cloud = mesh.sample_points_uniformly(number_of_points=sample_points)\n",
    "    else:\n",
    "        # 使用网格顶点创建点云\n",
    "        point_cloud = o3d.geometry.PointCloud()\n",
    "        point_cloud.points = mesh.vertices\n",
    "        point_cloud.colors = mesh.vertex_colors if mesh.has_vertex_colors() else None\n",
    "        point_cloud.normals = mesh.vertex_normals if mesh.has_vertex_normals() else None\n",
    "    \n",
    "    print(f\"点云创建完成: {len(point_cloud.points)}个点\")\n",
    "    \n",
    "    return point_cloud\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd951f27",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55aacdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DISPLAY\"] = \":0\"\n",
    "only_table_index = 1\n",
    "depth_threshold = 2\n",
    "root_path = Path(root_path)\n",
    "# only_table_intrinsics = np.load(root_path / \"only_table/intrinsics.npz\", allow_pickle=True)\n",
    "only_table_intrinsics = np.load(root_path / \"intrinsics.npz\", allow_pickle=True)\n",
    "# rgb_only_table_path = list((root_path / \"only_table/color_0\").glob(\"*.png\"))[only_table_index]\n",
    "# depth_only_table_path = list((root_path / \"only_table/depth_0\").glob(\"*.npy\"))[only_table_index]\n",
    "# print(cv2.imread(str(rgb_only_table_path)))\n",
    "rgb_only_table = cv2.cvtColor(cv2.imread(str(rgb_only_table_path)), cv2.COLOR_BGR2RGB)\n",
    "depth_only_table = np.load(str(depth_only_table_path))\n",
    "intrinsics = get_intr_matrix(only_table_intrinsics)\n",
    "pcd_table_only, pcd_np_clean_table = depth_to_pointcloud(rgb_only_table, depth_only_table, intrinsics, depth_threshold)\n",
    "to_vis = []\n",
    "to_vis.append(pcd_table_only)\n",
    "frame_base = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "to_vis.append(frame_base)\n",
    "o3d.visualization.draw_geometries(to_vis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0ad5f",
   "metadata": {},
   "source": [
    "## Get GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff6f0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载OBJ文件: /home/minghuan/ppt_learning/logs/gt/T_block_left/T_block_left.obj\n",
      "网格加载完成: 66个顶点, 40个三角形\n",
      "对网格进行采样: 50000个点\n",
      "点云创建完成: 50000个点\n",
      "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "gt_pcd = load_obj_as_pointcloud(gt_obj_file_path, sample_points=50000)\n",
    "translation = np.array([(0.3395, 0, 0.529)])\n",
    "# 创建平移矩阵\n",
    "transform = np.eye(4)  # 创建4x4单位矩阵\n",
    "transform[:3, 3] = translation  # 设置平移部分\n",
    "# 应用变换\n",
    "gt_pcd.transform(transform)\n",
    "transform = np.eye(4)  # 创建4x4单位矩阵\n",
    "transform[:3, :3] = R.from_euler('xyz', [-90, 0, 0], degrees=True).as_matrix()\n",
    "gt_pcd.transform(transform)\n",
    "\n",
    "vis = []\n",
    "frame_base = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "vis.append(gt_pcd)\n",
    "vis.append(frame_base)\n",
    "o3d.visualization.draw_geometries(vis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb3a10",
   "metadata": {},
   "source": [
    "## Init Aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ccbbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[789.46906 427.7479 ]]\n",
      "\n",
      " [[699.93463 406.55243]]\n",
      "\n",
      " [[666.4892  338.48077]]\n",
      "\n",
      " [[649.64514 337.85358]]\n",
      "\n",
      " [[631.5763  336.5893 ]]\n",
      "\n",
      " [[787.6045  311.09576]]\n",
      "\n",
      " [[787.53455 294.72025]]]\n",
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-9.99163979e-01, -4.08807455e-02, -3.29391964e-04,\n",
       "         3.88910343e-01],\n",
       "       [ 3.87968063e-02, -9.50709366e-01,  3.07646727e-01,\n",
       "        -4.65329402e-01],\n",
       "       [-1.28899836e-02,  3.07376749e-01,  9.51500595e-01,\n",
       "        -1.97107100e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def estimate_pose(image, charuco_dict, intrinsics_matrix, dist_coeffs, board):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    detector_params = cv2.aruco.DetectorParameters()\n",
    "    aruco_detector = cv2.aruco.ArucoDetector(charuco_dict, detector_params)\n",
    "    corners, ids, _ = aruco_detector.detectMarkers(image)\n",
    "\n",
    "    charucodetector = cv2.aruco.CharucoDetector(board)\n",
    "    charuco_corners, charuco_ids, marker_corners, marker_ids = charucodetector.detectBoard(image)\n",
    "    # print('Detected markers: ', ids)\n",
    "    print(charuco_corners)\n",
    "    print(len(marker_corners))\n",
    "    if charuco_ids is not None and len(charuco_corners) > 3:\n",
    "        valid, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(charuco_corners, charuco_ids, board, intrinsics_matrix, dist_coeffs, None, None)\n",
    "        if valid:\n",
    "            R_target2cam = cv2.Rodrigues(rvec)[0]\n",
    "            t_target2cam = tvec.reshape(3, 1)\n",
    "            target2cam = np.eye(4)\n",
    "            target2cam[:3, :3] = R_target2cam\n",
    "            target2cam[:3, 3] = t_target2cam.reshape(-1)\n",
    "            return np.linalg.inv(target2cam)\n",
    "    return None\n",
    "\n",
    "image = cv2.imread(\"/home/minghuan/ppt_learning/logs/photos/2025-05-06_18-20-48/color_1/1746526856232.png\")\n",
    "charuco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)\n",
    "board = cv2.aruco.CharucoBoard((12, 10), 0.04, 0.03, charuco_dict)\n",
    "cam_2_marker_init = estimate_pose(image, charuco_dict, intrinsics, np.zeros(5), board)\n",
    "cam_2_marker_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719017a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fe1e396",
   "metadata": {},
   "source": [
    "## Align by ICP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f1bd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n",
      "Initial alignment\n",
      "[[-9.99163979e-01 -4.08807455e-02 -3.29391964e-04  3.88910343e-01]\n",
      " [ 3.87968063e-02 -9.50709366e-01  3.07646727e-01 -4.65329402e-01]\n",
      " [-1.28899836e-02  3.07376749e-01  9.51500595e-01 -1.97107100e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      "Apply point-to-point ICP\n",
      "RegistrationResult with fitness=0.000000e+00, inlier_rmse=0.000000e+00, and correspondence_set size of 0\n",
      "Access transformation to get result.\n",
      "Transformation is:\n",
      "[[-9.99163979e-01 -4.08807455e-02 -3.29391964e-04  3.88910343e-01]\n",
      " [ 3.87968063e-02 -9.50709366e-01  3.07646727e-01 -4.65329402e-01]\n",
      " [-1.28899836e-02  3.07376749e-01  9.51500595e-01 -1.97107100e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import open3d as o3d\n",
    "import copy\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "\n",
    "draw_registration_result(pcd_table_only, gt_pcd, cam_2_marker_init)\n",
    "print(\"Initial alignment\")\n",
    "print(cam_2_marker_init)\n",
    "threshold = 0.01\n",
    "cam_2_marker_evaluation = o3d.pipelines.registration.evaluate_registration(\n",
    "    pcd_table_only, gt_pcd, threshold, cam_2_marker_init)\n",
    "print(cam_2_marker_evaluation)\n",
    "print(\"Apply point-to-point ICP\")\n",
    "reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "    pcd_table_only, gt_pcd, threshold, cam_2_marker_init,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "    o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=20000))\n",
    "\n",
    "print(reg_p2p)\n",
    "print(\"Transformation is:\")\n",
    "print(reg_p2p.transformation)\n",
    "draw_registration_result(pcd_table_only, gt_pcd, reg_p2p.transformation)\n",
    "camera_2_marker = reg_p2p.transformation\n",
    "np.save(Path(rgb_only_table_path).parent.parent / \"camera_2_table.npy\", camera_2_marker)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
